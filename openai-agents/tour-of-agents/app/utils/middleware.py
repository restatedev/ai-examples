import asyncio
import json

import agents
import restate

from agents import (
    Usage,
    Model,
    default_tool_error_function,
    RunContextWrapper,
    AgentsException,
    Runner,
    RunConfig,
    ModelSettings,
    Agent,
    TContext,
    RunResult,
    AgentBase,
)
from agents.function_schema import DocstringStyle
from agents.models.multi_provider import MultiProvider
from agents.items import TResponseStreamEvent, TResponseOutputItem
from agents.memory.session import SessionABC
from agents.items import TResponseInputItem
from typing import List, Any, overload, Callable
from typing import AsyncIterator

from agents.tool import ToolFunction, ToolErrorFunction, FunctionTool
from agents.tool_context import ToolContext
from agents.util._types import MaybeAwaitable
from pydantic import BaseModel
from restate.vm import SuspendedException


# The OpenAI ModelResponse class is a dataclass with Pydantic fields.
# The Restate SDK cannot serialize this. So we turn the ModelResponse int a Pydantic model.
class RestateModelResponse(BaseModel):
    output: list[TResponseOutputItem]
    """A list of outputs (messages, tool calls, etc) generated by the model"""

    usage: Usage
    """The usage information for the response."""

    response_id: str | None
    """An ID for the response which can be used to refer to the response in subsequent calls to the
    model. Not supported by all model providers.
    If using OpenAI models via the Responses API, this is the `response_id` parameter, and it can
    be passed to `Runner.run`.
    """

    def to_input_items(self) -> list[TResponseInputItem]:
        return [it.model_dump(exclude_unset=True) for it in self.output]  # type: ignore


class DurableModelCalls(MultiProvider):
    """
    A Restate model provider that wraps the OpenAI SDK's default MultiProvider.
    """

    def __init__(self, ctx: restate.Context, max_retries: int | None = 3):
        super().__init__()
        self.ctx = ctx
        self.max_retries = max_retries

    def get_model(self, model_name: str | None) -> Model:
        return RestateModelWrapper(
            self.ctx, super().get_model(model_name or None), self.max_retries
        )


class RestateModelWrapper(Model):
    """
    A wrapper around the OpenAI SDK's Model that persists LLM calls in the Restate journal.
    """

    def __init__(self, ctx: restate.Context, model: Model, max_retries: int | None = 3):
        self.ctx = ctx
        self.model = model
        self.model_name = f"RestateModelWrapper"
        self.max_retries = max_retries

    async def get_response(self, *args, **kwargs) -> RestateModelResponse:
        async def call_llm() -> RestateModelResponse:
            resp = await self.model.get_response(*args, **kwargs)
            return RestateModelResponse(
                output=resp.output,
                usage=resp.usage,
                response_id=resp.response_id,
            )

        return await self.ctx.run_typed(
            "call LLM", call_llm, restate.RunOptions(max_attempts=self.max_retries)
        )

    def stream_response(self, *args, **kwargs) -> AsyncIterator[TResponseStreamEvent]:
        raise restate.TerminalError(
            "Streaming is not supported in Restate. Use `get_response` instead."
        )


class RestateSession(SessionABC):
    """Restate session implementation following the Session protocol."""

    def __init__(
        self,
        session_id: str,
        ctx: (
            restate.ObjectContext
            | restate.ObjectSharedContext
            | restate.WorkflowContext
            | restate.WorkflowSharedContext
        ),
        current_items: List[TResponseInputItem],
    ):
        self.session_id = session_id
        self.ctx = ctx
        self.current_items = current_items

    @classmethod
    async def create(
        cls,
        session_id: str,
        ctx: (
            restate.ObjectContext
            | restate.ObjectSharedContext
            | restate.WorkflowContext
            | restate.WorkflowSharedContext
        ),
    ):
        current_items = await ctx.get("items", type_hint=List[TResponseInputItem]) or []
        return cls(session_id, ctx, current_items)

    async def get_items(self, limit: int | None = None) -> List[TResponseInputItem]:
        """Retrieve conversation history for this session."""
        if limit is not None:
            return self.current_items[-limit:]
        return self.current_items

    async def add_items(self, items: List[TResponseInputItem]) -> None:
        """Store new items for this session."""
        # Your implementation here
        self.ctx.set("items", self.current_items + items)

    async def pop_item(self) -> TResponseInputItem | None:
        """Remove and return the most recent item from this session."""
        if self.current_items:
            item = self.current_items.pop()
            self.ctx.set("items", self.current_items)
            return item
        return None

    async def clear_session(self) -> None:
        """Clear all items for this session."""
        self.current_items = []
        self.ctx.clear("items")


class AgentsTerminalException(AgentsException, restate.TerminalError):
    """Exception that is both an AgentsException and a restate.TerminalError."""

    def __init__(self, *args: object) -> None:
        super().__init__(*args)


class AgentsSuspension(AgentsException, SuspendedException):
    """Exception that is both an AgentsException and a restate.TerminalError."""

    def __init__(self, *args: object) -> None:
        super().__init__(*args)


class AgentsAsyncioSuspension(AgentsException, asyncio.CancelledError):
    """Exception that is both an AgentsException and a restate.TerminalError."""

    def __init__(self, *args: object) -> None:
        super().__init__(*args)


def raise_restate_errors(context: RunContextWrapper[Any], error: Exception) -> str:
    """A custom function to provide a user-friendly error message."""
    # Raise terminal errors and cancellations
    if isinstance(error, restate.TerminalError):
        # For the agent SDK it needs to be an AgentsException, for restate it needs to be a TerminalError
        # so we create a new exception that inherits from both
        raise AgentsTerminalException(error.message)

    # Raise suspensions
    if isinstance(error, SuspendedException):
        raise AgentsSuspension(error)

    # Next Python SDK release will use CancelledError for suspensions
    if isinstance(error, asyncio.CancelledError):
        raise AgentsAsyncioSuspension(error)

    # Feed all other errors back to the agent
    return default_tool_error_function(context, error)


@overload
def restate_function_tool(
    func: ToolFunction[...],
    *,
    name_override: str | None = None,
    description_override: str | None = None,
    docstring_style: DocstringStyle | None = None,
    use_docstring_info: bool = True,
    failure_error_function: ToolErrorFunction | None = None,
    strict_mode: bool = True,
    is_enabled: (
        bool | Callable[[RunContextWrapper[Any], AgentBase], MaybeAwaitable[bool]]
    ) = True,
) -> FunctionTool:
    """Overload for usage as @function_tool (no parentheses)."""
    ...


@overload
def restate_function_tool(
    *,
    name_override: str | None = None,
    description_override: str | None = None,
    docstring_style: DocstringStyle | None = None,
    use_docstring_info: bool = True,
    failure_error_function: ToolErrorFunction | None = None,
    strict_mode: bool = True,
    is_enabled: (
        bool | Callable[[RunContextWrapper[Any], AgentBase], MaybeAwaitable[bool]]
    ) = True,
) -> Callable[[ToolFunction[...]], FunctionTool]:
    """Overload for usage as @function_tool(...)."""
    ...


def restate_function_tool(
    func: ToolFunction[...] | None = None,
    *,
    name_override: str | None = None,
    description_override: str | None = None,
    docstring_style: DocstringStyle | None = None,
    use_docstring_info: bool = True,
    failure_error_function: ToolErrorFunction | None = default_tool_error_function,
    strict_mode: bool = True,
    is_enabled: (
        bool | Callable[[RunContextWrapper[Any], AgentBase], MaybeAwaitable[bool]]
    ) = True,
) -> FunctionTool | Callable[[ToolFunction[...]], FunctionTool]:
    def _raise_suspensions(context: RunContextWrapper[Any], error: Exception) -> str:
        """A custom function to provide a user-friendly error message."""
        # Raise terminal errors and cancellations
        if isinstance(error, restate.TerminalError):
            # For the agent SDK it needs to be an AgentsException, for restate it needs to be a TerminalError
            # so we create a new exception that inherits from both
            raise AgentsTerminalException(error.message)

        # Raise suspensions
        if isinstance(error, SuspendedException):
            raise AgentsSuspension(error)

        # Next Python SDK release will use CancelledError for suspensions
        if isinstance(error, asyncio.CancelledError):
            raise AgentsAsyncioSuspension(error)

        # Feed all other errors back to the agent
        return failure_error_function(context, error)

    return agents.function_tool(
        func=func,
        name_override=name_override,
        description_override=description_override,
        docstring_style=docstring_style,
        use_docstring_info=use_docstring_info,
        failure_error_function=_raise_suspensions,
        strict_mode=strict_mode,
        is_enabled=is_enabled,
    )


class RestateRunner:
    """
    A wrapper around Runner.run that automatically configures RunConfig for Restate contexts.

    This class automatically sets up the appropriate model provider (DurableModelCalls) and
    model settings, taking over any model and model_settings configuration provided in the
    original RunConfig.
    """

    @staticmethod
    async def run(
        restate_context: restate.Context,
        starting_agent: Agent[TContext],
        *args: object,
        run_config: RunConfig | None = None,
        **kwargs,
    ) -> RunResult:
        """
        Run an agent with automatic Restate configuration.

        Args:
            restate_context: The Restate context
            starting_agent: The agent to run
            input: The input message for the agent
            context: The Restate context
            run_config: Optional RunConfig (model and model_provider will be overridden)
            model: Optional model to use (defaults to "gpt-4o")
            model_settings: Optional model settings (defaults to parallel_tool_calls=False)
            **kwargs: Additional arguments to pass to Runner.run

        Returns:
            The result from Runner.run
        """

        # Set durable model calls and disable parallel tool calls
        effective_run_config = run_config or RunConfig()
        effective_run_config.model_provider = DurableModelCalls(restate_context)
        effective_run_config.model_settings = (
            effective_run_config.model_settings or ModelSettings()
        )
        effective_run_config.model_settings.parallel_tool_calls = False

        return await Runner.run(
            starting_agent, *args, run_config=effective_run_config, **kwargs
        )
